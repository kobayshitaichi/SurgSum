{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.config import get_config\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from logging import getLogger\n",
    "\n",
    "\n",
    "__all__ = [\"get_dataset\"]\n",
    "logger = getLogger(__name__)\n",
    "config = get_config('/mnt/sda1/Summarization/SurgSum/result/fps_sampling=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=20-aug_ver=1/config.yaml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path(config.dataset_dir) / \"csv\"\n",
    "dirs = list(csv_path.glob('*csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video00 before subsampling: 131840\n",
      "video00 after subsampling: 4395\n",
      "video01 before subsampling: 57063\n",
      "video01 after subsampling: 1903\n",
      "video02 before subsampling: 117343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:00<00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video02 after subsampling: 3912\n",
      "video03 before subsampling: 146863\n",
      "video03 after subsampling: 4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video05 before subsampling: 126155\n",
      "video05 after subsampling: 4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.DataFrame()\n",
    "for i, path in enumerate(tqdm(sorted(dirs))):\n",
    "    file_name = path.stem\n",
    "    # if file_name != 'video01':\n",
    "    #     continue\n",
    "    tmp = pd.read_csv(path)\n",
    "    print(f'{file_name} before subsampling: {len(tmp)}')\n",
    "\n",
    "    tmp['video_idx'] = int(file_name[-2:])  \n",
    "    img_path = os.path.join(config.dataset_dir, 'video_split', file_name)\n",
    "    tmp['file_name'] = sorted(os.listdir(img_path)[:len(tmp)])\n",
    "    \n",
    "    if config.val_vid_idx == int(file_name[-2:]):\n",
    "        tmp['stage'] = 'val'\n",
    "        factor = int(30 / config.fps_sampling_test)\n",
    "    else:\n",
    "        tmp['stage'] = 'train'\n",
    "        factor = int(30 / config.fps_sampling)\n",
    "    tmp = tmp.iloc[::factor]\n",
    "    print(f'{file_name} after subsampling: {len(tmp)}')\n",
    "    all_df = pd.concat([all_df, tmp], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>time</th>\n",
       "      <th>field</th>\n",
       "      <th>phase</th>\n",
       "      <th>summary</th>\n",
       "      <th>video_idx</th>\n",
       "      <th>file_name</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0:00:00.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000001.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0:00:01.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000031.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0:00:02.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000061.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0:00:03.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000091.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>0:00:04.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000121.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126030</th>\n",
       "      <td>126030</td>\n",
       "      <td>1:10:01.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>video05_173704.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126060</th>\n",
       "      <td>126060</td>\n",
       "      <td>1:10:02.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>video05_173742.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126090</th>\n",
       "      <td>126090</td>\n",
       "      <td>1:10:03.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>video05_173787.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126120</th>\n",
       "      <td>126120</td>\n",
       "      <td>1:10:04.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>video05_173826.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126150</th>\n",
       "      <td>126150</td>\n",
       "      <td>1:10:05.00</td>\n",
       "      <td>0</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>video05_173866.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19312 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frame        time  field       phase  summary  video_idx  \\\n",
       "0            0  0:00:00.00  False  irrelevant      0.0          0   \n",
       "30          30  0:00:01.00  False  irrelevant     -1.0          0   \n",
       "60          60  0:00:02.00  False  irrelevant     -1.0          0   \n",
       "90          90  0:00:03.00  False  irrelevant     -1.0          0   \n",
       "120        120  0:00:04.00  False  irrelevant     -1.0          0   \n",
       "...        ...         ...    ...         ...      ...        ...   \n",
       "126030  126030  1:10:01.00  False  irrelevant     -1.0          5   \n",
       "126060  126060  1:10:02.00  False  irrelevant     -1.0          5   \n",
       "126090  126090  1:10:03.00  False  irrelevant     -1.0          5   \n",
       "126120  126120  1:10:04.00  False  irrelevant     -1.0          5   \n",
       "126150  126150  1:10:05.00      0  irrelevant     -1.0          5   \n",
       "\n",
       "                 file_name  stage  \n",
       "0       video00_000001.png  train  \n",
       "30      video00_000031.png  train  \n",
       "60      video00_000061.png  train  \n",
       "90      video00_000091.png  train  \n",
       "120     video00_000121.png  train  \n",
       "...                    ...    ...  \n",
       "126030  video05_173704.png  train  \n",
       "126060  video05_173742.png  train  \n",
       "126090  video05_173787.png  train  \n",
       "126120  video05_173826.png  train  \n",
       "126150  video05_173866.png  train  \n",
       "\n",
       "[19312 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>time</th>\n",
       "      <th>field</th>\n",
       "      <th>phase</th>\n",
       "      <th>summary</th>\n",
       "      <th>video_idx</th>\n",
       "      <th>file_name</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0:00:00.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000001.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0:00:01.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000031.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0:00:02.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000061.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0:00:03.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000091.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>0:00:04.00</td>\n",
       "      <td>False</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_000121.png</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame        time  field       phase  summary  video_idx  \\\n",
       "0        0  0:00:00.00  False  irrelevant      0.0          0   \n",
       "30      30  0:00:01.00  False  irrelevant     -1.0          0   \n",
       "60      60  0:00:02.00  False  irrelevant     -1.0          0   \n",
       "90      90  0:00:03.00  False  irrelevant     -1.0          0   \n",
       "120    120  0:00:04.00  False  irrelevant     -1.0          0   \n",
       "\n",
       "              file_name  stage  \n",
       "0    video00_000001.png  train  \n",
       "30   video00_000031.png  train  \n",
       "60   video00_000061.png  train  \n",
       "90   video00_000091.png  train  \n",
       "120  video00_000121.png  train  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "\n",
    "__all__ = [\"get_dataloader\"]\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class ExtractorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, config, stage=\"train\"):\n",
    "        self.stage = stage\n",
    "        self.df = df\n",
    "        self.df = self.df[self.df[\"stage\"] == self.stage]\n",
    "        self.config = config\n",
    "        self.class_labels = self.get_labels()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        video_name = \"video\" + str(row.video_idx).zfill(2)\n",
    "        data_path = os.path.join(self.config.dataset_dir, \"video_split\", video_name, row.file_name)\n",
    "        img = Image.open(data_path)\n",
    "        img = np.array(img)\n",
    "        if self.stage == 'train':\n",
    "            img = self.transform()(image=img)[\"image\"]\n",
    "        label = torch.tensor(self.class_labels[row.phase])\n",
    "\n",
    "        return img.float(), label.float()\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        class_labels = {}\n",
    "        for i,label in enumerate(self.df.phase.unique()):\n",
    "            class_labels[label] = i\n",
    "            print(label, i)\n",
    "        return class_labels\n",
    "\n",
    "    def transform(self):\n",
    "        transforms = [\n",
    "                A.Normalize(mean=(0,0,0), std=(1,1,1)),\n",
    "        ]\n",
    "        \n",
    "        if self.stage == 'train':\n",
    "            if self.config.aug_ver == 1:\n",
    "                transforms += [\n",
    "                A.RandomResizedCrop(always_apply=False, p=1.0, height=self.img_size, width=self.img_size, scale=(0.7, 1.2), ratio=(0.75, 1.3), interpolation=1),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                ]\n",
    "            elif self.config.aug_ver == 2:\n",
    "                transforms += [\n",
    "                    A.HorizontalFlip(p=0.3),\n",
    "                    A.VerticalFlip(p=0.3),\n",
    "                ]\n",
    "            \n",
    "        transforms.append(ToTensorV2(p=1))\n",
    "\n",
    "        return A.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irrelevant 0\n",
      "design 1\n",
      "anesthesia 2\n",
      "incision 3\n",
      "hemostasis 4\n",
      "dissection 5\n",
      "closure 6\n",
      "others 7\n"
     ]
    }
   ],
   "source": [
    "ds = ExtractorDataset(all_df, config, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 250, 250])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('/mnt/sda1/Summarization/SurgSum/result/fps_sampling=1-val_vid_idx=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=1-aug_ver=1/preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('/mnt/sda1/Summarization/SurgSum/result/fps_sampling=1-val_vid_idx=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=1-aug_ver=1/features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/sda1/Summarization/SurgSum/result/fps_sampling=1-val_vid_idx=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=1-aug_ver=1/processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>time</th>\n",
       "      <th>field</th>\n",
       "      <th>phase</th>\n",
       "      <th>summary</th>\n",
       "      <th>video_idx</th>\n",
       "      <th>file_name</th>\n",
       "      <th>stage</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3330</td>\n",
       "      <td>0:01:51.00</td>\n",
       "      <td>True</td>\n",
       "      <td>design</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_003331.png</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3360</td>\n",
       "      <td>0:01:52.00</td>\n",
       "      <td>True</td>\n",
       "      <td>design</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_003361.png</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3390</td>\n",
       "      <td>0:01:53.00</td>\n",
       "      <td>True</td>\n",
       "      <td>design</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_003391.png</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3420</td>\n",
       "      <td>0:01:54.00</td>\n",
       "      <td>True</td>\n",
       "      <td>design</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_003421.png</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3450</td>\n",
       "      <td>0:01:55.00</td>\n",
       "      <td>True</td>\n",
       "      <td>design</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_003451.png</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>131430</td>\n",
       "      <td>1:13:01.00</td>\n",
       "      <td>True</td>\n",
       "      <td>closure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_131432.png</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>131460</td>\n",
       "      <td>1:13:02.00</td>\n",
       "      <td>True</td>\n",
       "      <td>closure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_131462.png</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>131490</td>\n",
       "      <td>1:13:03.00</td>\n",
       "      <td>True</td>\n",
       "      <td>closure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_131492.png</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>131520</td>\n",
       "      <td>1:13:04.00</td>\n",
       "      <td>True</td>\n",
       "      <td>closure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_131522.png</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>131550</td>\n",
       "      <td>1:13:05.00</td>\n",
       "      <td>True</td>\n",
       "      <td>closure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>video00_131552.png</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frame        time  field    phase  summary  video_idx  \\\n",
       "0       3330  0:01:51.00   True   design      0.0          0   \n",
       "1       3360  0:01:52.00   True   design      0.0          0   \n",
       "2       3390  0:01:53.00   True   design      0.0          0   \n",
       "3       3420  0:01:54.00   True   design      0.0          0   \n",
       "4       3450  0:01:55.00   True   design      0.0          0   \n",
       "...      ...         ...    ...      ...      ...        ...   \n",
       "3452  131430  1:13:01.00   True  closure      0.0          0   \n",
       "3453  131460  1:13:02.00   True  closure      0.0          0   \n",
       "3454  131490  1:13:03.00   True  closure      0.0          0   \n",
       "3455  131520  1:13:04.00   True  closure      0.0          0   \n",
       "3456  131550  1:13:05.00   True  closure      0.0          0   \n",
       "\n",
       "               file_name  stage  y  \n",
       "0     video00_003331.png  train  0  \n",
       "1     video00_003361.png  train  0  \n",
       "2     video00_003391.png  train  0  \n",
       "3     video00_003421.png  train  0  \n",
       "4     video00_003451.png  train  0  \n",
       "...                  ...    ... ..  \n",
       "3452  video00_131432.png  train  5  \n",
       "3453  video00_131462.png  train  5  \n",
       "3454  video00_131492.png  train  5  \n",
       "3455  video00_131522.png  train  5  \n",
       "3456  video00_131552.png  train  5  \n",
       "\n",
       "[3457 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/sda1/Summarization/SurgSum/SummarizationDataset/csv/video06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75555, 80526)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/mnt/sda1/Summarization/SurgSum/SummarizationDataset/video_split/video06')), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90666.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75555 * 30 /25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closure       9999\n",
       "irrelenant       1\n",
       "Name: phase, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase[-10000:].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dissection          56116\n",
       "closure             35518\n",
       "incision            13913\n",
       "irrelevant_frame    12613\n",
       "anesthesia          10402\n",
       "hemostasis           5708\n",
       "design               3700\n",
       "Name: phase, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "110 * 60 * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8052"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2684*3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGL_SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.models import get_model\n",
    "from libs.config import get_config\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from logging import getLogger\n",
    "\n",
    "\n",
    "__all__ = [\"get_dataset\"]\n",
    "logger = getLogger(__name__)\n",
    "config = get_config('/mnt/sda1/Summarization/SurgSum/result/fps_sampling=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=20-aug_ver=1/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_idx</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3457</td>\n",
       "      <td>4695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4695</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7443</td>\n",
       "      <td>10401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_idx  start_idx  end_idx\n",
       "0          0          0     3457\n",
       "1          1       3457     4695\n",
       "2          2       4695     7443\n",
       "3          3       7443    10401"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'fps_sampling=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=20-aug_ver=1'\n",
    "feature_path = os.path.join('../result',data_dir)\n",
    "fe_df = pd.read_csv(os.path.join(feature_path,'processed_df.csv'))\n",
    "features = np.load(os.path.join(feature_path,'features.npy'))\n",
    "\n",
    "df = pd.DataFrame({\"video_idx\":[0,1,2,3]})\n",
    "start = []\n",
    "end = []\n",
    "for i in range(4):\n",
    "    start.append(fe_df[fe_df.video_idx==i].index[0])\n",
    "    end.append(fe_df[fe_df.video_idx==i].index[-1] + 1)\n",
    "df['start_idx'] = start\n",
    "df['end_idx'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class SumDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, config, stage=\"train\"):\n",
    "        self.stage = stage\n",
    "        self.config = config\n",
    "        self.data_dir = 'fps_sampling=1-batch_size=128-img_size=224-out_features=6-lr=0.0001-loss_fn=ib_focal-max_epoch=20-aug_ver=1'\n",
    "        train_vid_ids = [0,1,2]\n",
    "        val_vid_ids = [3]\n",
    "        feature_path = os.path.join('../result',self.data_dir)\n",
    "        self.fe_df = pd.read_csv(os.path.join(feature_path,'processed_df.csv'))\n",
    "        self.features = np.load(os.path.join(feature_path,'features.npy'))\n",
    "        self.gts = self.fe_df.summary\n",
    "        if self.stage=='train':\n",
    "            self.vid_ids = train_vid_ids\n",
    "        else:\n",
    "            self.vid_ids = val_vid_ids\n",
    "            \n",
    "        self.df = self.get_df()\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        start = row.start_idx\n",
    "        end = row.end_idx\n",
    "        \n",
    "        features = torch.Tensor(self.features[start:end])\n",
    "        gts = torch.Tensor(self.gts[start:end])\n",
    "\n",
    "        return features, gts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_df(self):\n",
    "        df = pd.DataFrame({\"video_idx\":self.vid_ids})\n",
    "        start = []\n",
    "        end = []\n",
    "        split = []\n",
    "        for i in self.vid_ids:\n",
    "            start.append(self.fe_df[self.fe_df.video_idx==i].index[0])\n",
    "            end.append(self.fe_df[self.fe_df.video_idx==i].index[-1] + 1)\n",
    "        df['start_idx'] = start\n",
    "        df['end_idx'] = end\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SumDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, gts = ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3457, 2048])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3457, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchvision import transforms as transforms\n",
    "from logging import getLogger\n",
    "import numpy as np\n",
    "\n",
    "__all__ = [\"lightningmodule\"]\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class ExtractorLitModule(pl.LightningModule):\n",
    "    # ネットワークモジュールなどの定義\n",
    "    def __init__(self, config, model=None, loss_fn=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.learning_rate = self.config.lr\n",
    "        self.features = np.zeros((0,2048))\n",
    "        self.preds = np.zeros((0))\n",
    "        self.init_metrics()\n",
    "\n",
    "\n",
    "\n",
    "    def init_metrics(self):\n",
    "        self.acc_phase = torchmetrics.Accuracy(task='multiclass',num_classes=self.config.out_features)\n",
    "        self.f1_phase = torchmetrics.F1Score(num_classes=self.config.out_features,task='multiclass',average='macro')\n",
    "\n",
    "    # オプティマイザの定義\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(self.parameters(), lr=self.learning_rate, weight_decay=self.config.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max = self.config.max_epoch,\n",
    "                eta_min = self.config.lr_min,\n",
    "                last_epoch = -1\n",
    "            )\n",
    "\n",
    "        # lr_scheduler_dict = {\"scheduler\": scheduler, \"intervalf1\"step\"}\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "    # ==================================================================\n",
    "    def forward(self, batch):\n",
    "        imgs = batch\n",
    "        stem, preds = self.model(imgs)\n",
    "        return stem, preds\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        preds, loss, acc, f1 = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_f1\", f1, on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            logger.info(f'train_acc {batch_idx}: {acc}')\n",
    "            logger.info(f'train_f1 {batch_idx}: {f1}')\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        preds, loss, acc, f1 = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            logger.info(f'val_acc {batch_idx}: {acc}')\n",
    "            logger.info(f'val_f1 {batch_idx}: {f1}')\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        with torch.no_grad():\n",
    "            imgs, labels = batch\n",
    "            stem, preds = self.model(imgs)\n",
    "            preds = F.softmax(preds)\n",
    "            preds = torch.argmax(preds, dim=1)\n",
    "        logger.info(self.features.shape)\n",
    "        logger.info(self.preds.shape)\n",
    "        self.features = np.concatenate([self.features,stem.cpu().detach().numpy()],0)\n",
    "        self.preds = np.concatenate([self.preds,np.asarray(preds.cpu()).squeeze()],0)\n",
    "\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        imgs, labels = batch\n",
    "        stem, preds = self.model(imgs)\n",
    "        if self.config.loss_fn == 'ib_focal':\n",
    "            loss = self.loss_fn(preds, labels, stem)\n",
    "        else:\n",
    "            loss = self.loss_fn(preds, labels)\n",
    "        acc = self.acc_phase(preds, labels)\n",
    "        f1 = self.f1_phase(preds, labels)\n",
    "        \n",
    "        for param_group in self.trainer.optimizers[0].param_groups:\n",
    "            lr = param_group[\"lr\"]\n",
    "        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        \n",
    "\n",
    "        return preds, loss, acc, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ab3e1625478820ce8e6eab39f778c70118865cbc392bc0f6e664f6b4f52763b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
